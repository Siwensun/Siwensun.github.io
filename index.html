<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Shanlin Sun (孙 山林) </title> <meta name="author" content="Shanlin Sun (孙 山林)"> <meta name="description" content=""> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png?5bb7d69b0d8789305d247ff6baeaaa85"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://siwensun.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Shanlin</span> Sun (孙 山林) </h1> <p class="desc">Into everything vision-related.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/personal_page_profile-480.webp 480w,/assets/img/personal_page_profile-800.webp 800w,/assets/img/personal_page_profile-1400.webp 1400w," sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/personal_page_profile.jpg?a7122ca2c3a28e7c27f523ee4c4c8f92" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="personal_page_profile.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <p>I am a 4th-year <strong>Ph.D. student</strong> in the <a href="https://cs.ics.uci.edu/" rel="external nofollow noopener" target="_blank">Department of Computer Science at University of California, Irvine</a> (UCI), advised by <a href="https://ics.uci.edu/~xhx/" rel="external nofollow noopener" target="_blank">Prof. Xiaohui Xie</a>. I obtained my Master’s degree from <a href="https://minghsiehece.usc.edu/" rel="external nofollow noopener" target="_blank">University of Southern California</a> (USC) in 2019 and my Bachelor’s degree from <a href="https://yqgdxy.buaa.edu.cn/" rel="external nofollow noopener" target="_blank">Beihang University</a> (BUAA) in 2017.</p> <p>My primary research interests are at the intersection of <strong>computer vision, computer graphics and generative AI</strong>. Additionally, I have been actively engaged in medical image analysis.</p> <p><strong>Currently</strong>, I am focusing on three research topics:</p> <ul> <li>Synthesizing diverse 4D data paired with <strong>detailed text descriptions</strong>,</li> <li>Reconstructing 3D/4D scenes from <strong>3D-inconsistent</strong> synthesized videos, and</li> <li> <strong>“Inverting”</strong> controllable generative models for perceptual understanding.</li> </ul> <p>I am open to research collaborations and job opportunities. Feel free to reach out to me via email at shanlins<span style="color:orange">[at]</span>uci<span style="color:orange">[dot]</span>edu.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jun 23, 2024</th> <td> Join NEC Labs America as Research Intern in Media Analytics team, mentored by <a href="https://bbzh.github.io/" rel="external nofollow noopener" target="_blank">Bingbing Zhuang</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 23, 2024</th> <td> Our paper <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Sun_LidaRF_Delving_into_Lidar_for_Neural_Radiance_Field_on_Street_CVPR_2024_paper.pdf" rel="external nofollow noopener" target="_blank">“LidaRF: Delving into Lidar for Neural Radiance Field on Street Scenes”</a> was selected as highlights of <a href="https://cvpr.thecvf.com/" rel="external nofollow noopener" target="_blank">CVPR 2024</a> and will be oral presented at <a href="https://agents4ad.github.io/" rel="external nofollow noopener" target="_blank">CVPR 2024 Workshop DDADS</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 05, 2024</th> <td> I passed my advancement exam. Committee members: <a href="https://ics.uci.edu/~xhx/" rel="external nofollow noopener" target="_blank">Prof. Xiaohui Xie</a> (Chair), <a href="http://acberg.com/" rel="external nofollow noopener" target="_blank">Prof. Alexander C. Berg</a>, <a href="https://ics.uci.edu/~ihler/index.html" rel="external nofollow noopener" target="_blank">Prof. Alexander Ihler</a> and <a href="https://sites.google.com/uci.edu/yanning-shen/home" rel="external nofollow noopener" target="_blank">Prof. Yanning Shen</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 26, 2024</th> <td> Our paper <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Sun_LidaRF_Delving_into_Lidar_for_Neural_Radiance_Field_on_Street_CVPR_2024_paper.pdf" rel="external nofollow noopener" target="_blank">“LidaRF: Delving into Lidar for Neural Radiance Field on Street Scenes”</a> and <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Le_Integrating_Efficient_Optimal_Transport_and_Functional_Maps_For_Unsupervised_Shape_CVPR_2024_paper.pdf" rel="external nofollow noopener" target="_blank">“Integrating efficient optimal transport and functional maps for unsupervised shape correspondence learning”</a> were accepted at <a href="https://cvpr.thecvf.com/" rel="external nofollow noopener" target="_blank">CVPR 2024</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 16, 2024</th> <td> Our paper <a href="https://openreview.net/forum?id=gxhRR8vUQb" rel="external nofollow noopener" target="_blank">“Diffeomorphic Mesh Deformation via Efficient Optimal Transport for Cortical Surface Reconstruction”</a> was accepted at <a href="https://iclr.cc/" rel="external nofollow noopener" target="_blank">ICLR 2024</a>. </td> </tr> </table> </div> </div> <h2> <a href="/blog/" style="color: inherit">latest posts</a> </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">May 14, 2024</th> <td> <a class="news-title" href="https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/" target="_blank" rel="external nofollow noopener">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 23, 2022</th> <td> <a class="news-title" href="https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2" target="_blank" rel="external nofollow noopener">Displaying External Posts on Your al-folio Blog</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">R&amp;O</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/r&amp;o21_wbnet-480.webp 480w,/assets/img/publication_preview/r&amp;o21_wbnet-800.webp 800w,/assets/img/publication_preview/r&amp;o21_wbnet-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/r&amp;o21_wbnet.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="r&amp;o21_wbnet.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="chen2021deep" class="col-sm-8"> <div class="title">A deep learning-based auto-segmentation system for organs-at-risk on whole-body computed tomography images for radiation therapy</div> <div class="author"> Xuming Chen, <em>Shanlin Sun</em>, Narisu Bai, and <span class="more-authors" title="click to view 8 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '8 more authors' ? 'Kun Han, Qianqian Liu, Shengyu Yao, Hao Tang, Chupeng Zhang, Zhipeng Lu, Qian Huang, others' : '8 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">8 more authors</span> </div> <div class="periodical"> <em>Radiotherapy and Oncology</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S0167814021062174" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">chen2021deep</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A deep learning-based auto-segmentation system for organs-at-risk on whole-body computed tomography images for radiation therapy}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xuming and Sun, Shanlin and Bai, Narisu and Han, Kun and Liu, Qianqian and Yao, Shengyu and Tang, Hao and Zhang, Chupeng and Lu, Zhipeng and Huang, Qian and others}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Radiotherapy and Oncology}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{160}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{175--184}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr22_ndf-480.webp 480w,/assets/img/publication_preview/cvpr22_ndf-800.webp 800w,/assets/img/publication_preview/cvpr22_ndf-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/cvpr22_ndf.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr22_ndf.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="sun2022topology" class="col-sm-8"> <div class="title">Topology-preserving shape reconstruction and registration via neural diffeomorphic flow</div> <div class="author"> <em>Shanlin Sun</em>, Kun Han, Deying Kong, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Hao Tang, Xiangyi Yan, Xiaohui Xie' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In </em> , Jun 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2203.08652" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Siwensun/Neural_Diffeomorphic_Flow%E2%80%93NDF" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sun2022topology</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Topology-preserving shape reconstruction and registration via neural diffeomorphic flow}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sun, Shanlin and Han, Kun and Kong, Deying and Tang, Hao and Yan, Xiangyi and Xie, Xiaohui}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computer Vision and Patern Recognition}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{20845-20855}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/hybrid_csr_teaser-480.webp 480w,/assets/img/publication_preview/hybrid_csr_teaser-800.webp 800w,/assets/img/publication_preview/hybrid_csr_teaser-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/hybrid_csr_teaser.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="hybrid_csr_teaser.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="sun2023hybrid" class="col-sm-8"> <div class="title">Hybrid-CSR: Coupling Explicit and Implicit Shape Representation for Cortical Surface Reconstruction</div> <div class="author"> <em>Shanlin Sun</em>, Thanh-Tung Le, Chenyu You, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Hao Tang, Kun Han, Haoyu Ma, Deying Kong, Xiangyi Yan, Xiaohui Xie' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>arXiv preprint</em>, Jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2307.12299" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">sun2023hybrid</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hybrid-CSR: Coupling Explicit and Implicit Shape Representation for Cortical Surface Reconstruction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sun, Shanlin and Le, Thanh-Tung and You, Chenyu and Tang, Hao and Han, Kun and Ma, Haoyu and Kong, Deying and Yan, Xiangyi and Xie, Xiaohui}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr24_lidarf-480.webp 480w,/assets/img/publication_preview/cvpr24_lidarf-800.webp 800w,/assets/img/publication_preview/cvpr24_lidarf-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/cvpr24_lidarf.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr24_lidarf.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="sun2024lidarf" class="col-sm-8"> <div class="title">LidaRF: Delving into Lidar for Neural Radiance Field on Street Scenes</div> <div class="author"> <em>Shanlin Sun</em>, Bingbing Zhuang, Ziyu Jiang, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Buyu Liu, Xiaohui Xie, Manmohan Chandraker' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In </em> , Jun 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2405.00900" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://siwensun.github.io/lidarf-project/" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sun2024lidarf</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{LidaRF: Delving into Lidar for Neural Radiance Field on Street Scenes}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sun, Shanlin and Zhuang, Bingbing and Jiang, Ziyu and Liu, Buyu and Xie, Xiaohui and Chandraker, Manmohan}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computer Vision and Patern Recognition}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{19563--19572}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%73%68%61%6E%6C%69%6E%73[%61%74]%75%63%69[%64%6F%74]%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=c6wKvwgAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/Siwensun" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/shanlin-sun/" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> </div> <div class="contact-note"></div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Shanlin Sun (孙 山林). Last updated: June 17, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?06cae41083477f121be8cd9797ad8e2f"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-cv",title:"cv",description:"The PDF is probably easier to read.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:"Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra",description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:"Displaying External Posts on Your al-folio Blog",description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"news-join-nec-labs-america-as-research-intern-in-media-analytics-team-mentored-by-lt-a-href-quot-https-bbzh-github-io-quot-gt-bingbing-zhuang-lt-a-gt",title:"Join NEC Labs America as Research Intern in Media Analytics team, mentored by &lt;a href=&quot;https://bbzh.github.io/&quot;&gt;Bingbing Zhuang&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-openaccess-thecvf-com-content-cvpr2024-papers-sun-lidarf-delving-into-lidar-for-neural-radiance-field-on-street-cvpr-2024-paper-pdf-quot-gt-lidarf-delving-into-lidar-for-neural-radiance-field-on-street-scenes-lt-a-gt-was-selected-as-highlights-of-lt-a-href-quot-https-cvpr-thecvf-com-quot-gt-cvpr-2024-lt-a-gt-and-will-be-oral-presented-at-lt-a-href-quot-https-agents4ad-github-io-quot-gt-cvpr-2024-workshop-ddads-lt-a-gt",title:"Our paper &lt;a href=&quot;https://openaccess.thecvf.com/content/CVPR2024/papers/Sun_LidaRF_Delving_into_Lidar_for_Neural_Radiance_Field_on_Street_CVPR_2024_paper.pdf&quot;&gt;\u201cLidaRF: Delving into Lidar for Neural Radiance Field on Street Scenes\u201d&lt;/a&gt; was selected as highlights of &lt;a href=&quot;https://cvpr.thecvf.com/&quot;&gt;CVPR 2024&lt;/a&gt; and will be oral presented at &lt;a href=&quot;https://agents4ad.github.io/&quot;&gt;CVPR 2024 Workshop DDADS&lt;/a&gt;.",description:"",section:"News"},{id:"news-i-passed-my-advancement-exam-committee-members-lt-a-href-quot-https-ics-uci-edu-xhx-quot-gt-prof-xiaohui-xie-lt-a-gt-chair-lt-a-href-quot-http-acberg-com-quot-gt-prof-alexander-c-berg-lt-a-gt-lt-a-href-quot-https-ics-uci-edu-ihler-index-html-quot-gt-prof-alexander-ihler-lt-a-gt-and-lt-a-href-quot-https-sites-google-com-uci-edu-yanning-shen-home-quot-gt-prof-yanning-shen-lt-a-gt",title:"I passed my advancement exam. Committee members: &lt;a href=&quot;https://ics.uci.edu/~xhx/&quot;&gt;Prof. Xiaohui Xie&lt;/a&gt; (Chair), &lt;a href=&quot;http://acberg.com/&quot;&gt;Prof. Alexander C. Berg&lt;/a&gt;, &lt;a href=&quot;https://ics.uci.edu/~ihler/index.html&quot;&gt;Prof. Alexander Ihler&lt;/a&gt; and &lt;a href=&quot;https://sites.google.com/uci.edu/yanning-shen/home&quot;&gt;Prof. Yanning Shen&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-openaccess-thecvf-com-content-cvpr2024-papers-sun-lidarf-delving-into-lidar-for-neural-radiance-field-on-street-cvpr-2024-paper-pdf-quot-gt-lidarf-delving-into-lidar-for-neural-radiance-field-on-street-scenes-lt-a-gt-and-lt-a-href-quot-https-openaccess-thecvf-com-content-cvpr2024-papers-le-integrating-efficient-optimal-transport-and-functional-maps-for-unsupervised-shape-cvpr-2024-paper-pdf-quot-gt-integrating-efficient-optimal-transport-and-functional-maps-for-unsupervised-shape-correspondence-learning-lt-a-gt-were-accepted-at-lt-a-href-quot-https-cvpr-thecvf-com-quot-gt-cvpr-2024-lt-a-gt",title:"Our paper &lt;a href=&quot;https://openaccess.thecvf.com/content/CVPR2024/papers/Sun_LidaRF_Delving_into_Lidar_for_Neural_Radiance_Field_on_Street_CVPR_2024_paper.pdf&quot;&gt;\u201cLidaRF: Delving into Lidar for Neural Radiance Field on Street Scenes\u201d&lt;/a&gt; and &lt;a href=&quot;https://openaccess.thecvf.com/content/CVPR2024/papers/Le_Integrating_Efficient_Optimal_Transport_and_Functional_Maps_For_Unsupervised_Shape_CVPR_2024_paper.pdf&quot;&gt;\u201cIntegrating efficient optimal transport and functional maps for unsupervised shape correspondence learning\u201d&lt;/a&gt; were accepted at &lt;a href=&quot;https://cvpr.thecvf.com/&quot;&gt;CVPR 2024&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-openreview-net-forum-id-gxhrr8vuqb-quot-gt-diffeomorphic-mesh-deformation-via-efficient-optimal-transport-for-cortical-surface-reconstruction-lt-a-gt-was-accepted-at-lt-a-href-quot-https-iclr-cc-quot-gt-iclr-2024-lt-a-gt",title:"Our paper &lt;a href=&quot;https://openreview.net/forum?id=gxhRR8vUQb&quot;&gt;\u201cDiffeomorphic Mesh Deformation via Efficient Optimal Transport for Cortical Surface Reconstruction\u201d&lt;/a&gt; was accepted at &lt;a href=&quot;https://iclr.cc/&quot;&gt;ICLR 2024&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-openaccess-thecvf-com-content-wacv2024-papers-yan-after-sam-adapting-sam-with-axial-fusion-transformer-for-medical-imaging-wacv-2024-paper-pdf-quot-gt-after-sam-lt-a-gt-lt-a-href-quot-https-openaccess-thecvf-com-content-wacv2024-papers-ma-cvthead-one-shot-controllable-head-avatar-with-vertex-feature-transformer-wacv-2024-paper-pdf-quot-gt-cvthead-lt-a-gt-and-lt-a-href-quot-https-openaccess-thecvf-com-content-wacv2024-papers-han-hybrid-neural-diffeomorphic-flow-for-shape-representation-and-generation-via-wacv-2024-paper-pdf-quot-gt-hndf-lt-a-gt-were-accepted-at-lt-a-href-quot-https-wacv2024-thecvf-com-quot-gt-wacv-2024-lt-a-gt",title:"Our paper &lt;a href=&quot;https://openaccess.thecvf.com/content/WACV2024/papers/Yan_AFTer-SAM_Adapting_SAM_With_Axial_Fusion_Transformer_for_Medical_Imaging_WACV_2024_paper.pdf&quot;&gt;AFTer-SAM&lt;/a&gt;, &lt;a href=&quot;https://openaccess.thecvf.com/content/WACV2024/papers/Ma_CVTHead_One-Shot_Controllable_Head_Avatar_With_Vertex-Feature_Transformer_WACV_2024_paper.pdf&quot;&gt;CVTHead&lt;/a&gt; and &lt;a href=&quot;https://openaccess.thecvf.com/content/WACV2024/papers/Han_Hybrid_Neural_Diffeomorphic_Flow_for_Shape_Representation_and_Generation_via_WACV_2024_paper.pdf&quot;&gt;HNDF&lt;/a&gt; were accepted at &lt;a href=&quot;https://wacv2024.thecvf.com&quot;&gt;WACV 2024&lt;/a&gt;.",description:"",section:"News"},{id:"news-join-nec-labs-america-as-research-intern-in-media-analytics-team-mentored-by-lt-a-href-quot-https-bbzh-github-io-quot-gt-bingbing-zhuang-lt-a-gt-and-lt-a-href-quot-https-geekjzy-github-io-quot-gt-ziyu-jiang-lt-a-gt",title:"Join NEC Labs America as Research Intern in Media Analytics team, mentored by &lt;a href=&quot;https://bbzh.github.io/&quot;&gt;Bingbing Zhuang&lt;/a&gt; and &lt;a href=&quot;https://geekjzy.github.io/&quot;&gt;Ziyu Jiang&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-arxiv-org-pdf-2304-04106-quot-gt-medgen3d-a-deep-generative-framework-for-paired-3d-image-and-mask-generation-lt-a-gt-and-lt-a-href-quot-https-arxiv-org-pdf-2304-03406-quot-gt-localized-region-contrast-for-enhancing-self-supervised-learning-in-medical-image-segmentation-lt-a-gt-were-accepted-at-lt-a-href-quot-https-conferences-miccai-org-2023-en-quot-gt-miccai-2023-lt-a-gt",title:"Our paper &lt;a href=&quot;https://arxiv.org/pdf/2304.04106&quot;&gt;\u201cMedgen3d: A deep generative framework for paired 3d image and mask generation\u201d&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/pdf/2304.03406&quot;&gt;\u201cLocalized Region Contrast for Enhancing Self-supervised Learning in Medical Image Segmentation\u201d&lt;/a&gt; were accepted at &lt;a href=&quot;https://conferences.miccai.org/2023/en/&quot;&gt;MICCAI 2023&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-openaccess-thecvf-com-content-wacv2023-papers-han-diffeomorphic-image-registration-with-neural-velocity-field-wacv-2023-paper-pdf-quot-gt-diffeomorphic-image-registration-with-neural-velocity-field-lt-a-gt-and-lt-a-href-quot-https-openaccess-thecvf-com-content-wacv2023-papers-yan-representation-recovering-for-self-supervised-pre-training-on-medical-images-wacv-2023-paper-pdf-quot-gt-representation-recovering-for-self-supervised-pre-training-on-medical-images-lt-a-gt-were-accepted-at-lt-a-href-quot-https-wacv2023-thecvf-com-home-quot-gt-wacv-2023-lt-a-gt",title:"Our paper &lt;a href=&quot;https://openaccess.thecvf.com/content/WACV2023/papers/Han_Diffeomorphic_Image_Registration_With_Neural_Velocity_Field_WACV_2023_paper.pdf&quot;&gt;\u201cDiffeomorphic Image Registration with Neural Velocity Field\u201d&lt;/a&gt; and &lt;a href=&quot;https://openaccess.thecvf.com/content/WACV2023/papers/Yan_Representation_Recovering_for_Self-Supervised_Pre-Training_on_Medical_Images_WACV_2023_paper.pdf&quot;&gt;\u201cRepresentation recovering for self-supervised pre-training on medical images\u201d&lt;/a&gt; were accepted at &lt;a href=&quot;https://wacv2023.thecvf.com/home&quot;&gt;WACV 2023&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-arxiv-org-pdf-2209-10840-quot-gt-identity-aware-hand-mesh-estimation-and-personalization-from-rgb-images-lt-a-gt-was-accepted-at-lt-a-href-quot-https-eccv2022-ecva-net-quot-gt-eccv-2022-lt-a-gt",title:"Our paper &lt;a href=&quot;https://arxiv.org/pdf/2209.10840&quot;&gt;\u201cIdentity-aware hand mesh estimation and personalization from rgb images\u201d&lt;/a&gt; was accepted at &lt;a href=&quot;https://eccv2022.ecva.net/&quot;&gt;ECCV 2022&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-openaccess-thecvf-com-content-cvpr2022-papers-sun-topology-preserving-shape-reconstruction-and-registration-via-neural-diffeomorphic-flow-cvpr-2022-paper-pdf-quot-gt-topology-preserving-shape-reconstruction-and-registration-via-neural-diffeomorphic-flow-lt-a-gt-was-accepted-at-lt-a-href-quot-https-cvpr2022-thecvf-com-quot-gt-cvpr-2022-lt-a-gt",title:"Our paper &lt;a href=&quot;https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Topology-Preserving_Shape_Reconstruction_and_Registration_via_Neural_Diffeomorphic_Flow_CVPR_2022_paper.pdf&quot;&gt;\u201cTopology-preserving shape reconstruction and registration via neural diffeomorphic flow\u201d&lt;/a&gt; was accepted at &lt;a href=&quot;https://cvpr2022.thecvf.com/&quot;&gt;CVPR 2022&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-openaccess-thecvf-com-content-wacv2022-papers-yan-after-unet-axial-fusion-transformer-unet-for-medical-image-segmentation-wacv-2022-paper-pdf-quot-gt-after-unet-axial-fusion-transformer-unet-for-medical-image-segmentation-lt-a-gt-was-accepted-at-lt-a-href-quot-https-wacv2022-thecvf-com-home-quot-gt-wacv-2022-lt-a-gt",title:"Our paper &lt;a href=&quot;https://openaccess.thecvf.com/content/WACV2022/papers/Yan_AFTer-UNet_Axial_Fusion_Transformer_UNet_for_Medical_Image_Segmentation_WACV_2022_paper.pdf&quot;&gt;\u201cAfter-unet: Axial fusion transformer unet for medical image segmentation\u201d&lt;/a&gt; was accepted at &lt;a href=&quot;https://wacv2022.thecvf.com/home&quot;&gt;WACV 2022&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-www-sciencedirect-com-science-article-pii-s0167814021062174-quot-gt-a-deep-learning-based-auto-segmentation-system-for-organs-at-risk-on-whole-body-computed-tomography-images-for-radiation-therapy-lt-a-gt-was-accepted-at-lt-a-href-quot-https-www-sciencedirect-com-journal-radiotherapy-and-oncology-quot-gt-radiotherapy-and-oncology-lt-a-gt",title:"Our paper &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0167814021062174&quot;&gt;\u201cA deep learning-based auto-segmentation system for organs-at-risk on whole-body computed tomography images for radiation therapy\u201d&lt;/a&gt; was accepted at &lt;a href=&quot;https://www.sciencedirect.com/journal/radiotherapy-and-oncology&quot;&gt;Radiotherapy and Oncology&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-arxiv-org-pdf-2001-04446-quot-gt-attentionanatomy-a-unified-framework-for-whole-body-organs-at-risk-segmentation-using-multiple-partially-annotated-datasets-lt-a-gt-was-accepted-at-lt-a-href-quot-http-2020-biomedicalimaging-org-quot-gt-isbi-2020-lt-a-gt",title:"Our paper &lt;a href=&quot;https://arxiv.org/pdf/2001.04446&quot;&gt;\u201cAttentionanatomy: A Unified Framework for Whole-Body Organs at Risk Segmentation Using Multiple Partially Annotated Datasets\u201d&lt;/a&gt; was accepted at &lt;a href=&quot;http://2020.biomedicalimaging.org/&quot;&gt;ISBI 2020&lt;/a&gt;.",description:"",section:"News"},{id:"news-i-will-be-attending-university-of-california-irvine-for-a-cs-ph-d-this-fall-i-ll-be-working-at-the-intersection-of-deep-learning-and-medical-image-analysis-under-advisement-from-lt-a-href-quot-https-ics-uci-edu-xhx-quot-gt-prof-xiaohui-xie-lt-a-gt",title:"I will be attending University of California, Irvine for a CS Ph.D. this Fall. I\u2019ll be working at the intersection of deep learning and medical image analysis under advisement from &lt;a href=&quot;https://ics.uci.edu/~xhx/&quot;&gt;Prof. Xiaohui Xie&lt;/a&gt;.",description:"",section:"News"},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%73%68%61%6E%6C%69%6E%73[%61%74]%75%63%69[%64%6F%74]%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=c6wKvwgAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Siwensun","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/shanlin-sun/","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>