<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Shanlin Sun (孙 山林) </title> <meta name="author" content="Shanlin Sun (孙 山林)"> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png?5bb7d69b0d8789305d247ff6baeaaa85"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://siwensun.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Shanlin</span> Sun (孙 山林) </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <div class="publications"> <h2 class="bibliography">2026</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AAAI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/coma-480.webp 480w,/assets/img/publication_preview/coma-800.webp 800w,/assets/img/publication_preview/coma-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/coma.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="coma.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="sun2024coma" class="col-sm-8"> <div class="title">CoMA: Compositional Human Motion Generation with Multi-modal Agents</div> <div class="author"> <em>Shanlin Sun*</em>, Jiaqi Xu*, Gabriel Araujo*, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Shenghan Zhou*, Hanwen Zhang, Ziheng Huang, Chenyu You, Xiaohui Xie' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em></em> Jan 2026 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2412.07320" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Siwensun/CoMA" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://gabrie-l.github.io/coma-page/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">sun2024coma</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{CoMA: Compositional Human Motion Generation with Multi-modal Agents}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sun*, Shanlin and Xu*, Jiaqi and Araujo*, Gabriel and Zhou*, Shenghan and Zhang, Hanwen and Huang, Ziheng and You, Chenyu and Xie, Xiaohui}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Association for the Advancement of Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2026}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{How MLLM reasoning faciliates human motion generation, editing and self-correction?}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> <div class="notes"> <p>How MLLM reasoning faciliates human motion generation, editing and self-correction?</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2025</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/iccv25_ouroboros-480.webp 480w,/assets/img/publication_preview/iccv25_ouroboros-800.webp 800w,/assets/img/publication_preview/iccv25_ouroboros-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/iccv25_ouroboros.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="iccv25_ouroboros.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="sun2025ouroboros" class="col-sm-8"> <div class="title">Ouroboros: Single-step Diffusion Models for Cycle-consistent Forward and Inverse Rendering</div> <div class="author"> <em>Shanlin Sun*</em>, Yifan Wang*, Hanwen Zhang*, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Yifeng Xiong, Qin Ren, Ruogu Fang, Xiaohui Xie, Chenyu You' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em></em> Oct 2025 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2508.14461" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Y-Research-SBU/Ouroboros" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://siwensun.github.io/ouroboros-project/" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">sun2025ouroboros</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Ouroboros: Single-step Diffusion Models for Cycle-consistent Forward and Inverse Rendering}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sun*, Shanlin and Wang*, Yifan and Zhang*, Hanwen and Xiong, Yifeng and Ren, Qin and Fang, Ruogu and Xie, Xiaohui and You, Chenyu}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Computer Vision}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Finetune single-step diffusion models for cycle-consistent fast neural image decomposition and composition.}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> <div class="notes"> <p>Finetune single-step diffusion models for cycle-consistent fast neural image decomposition and composition.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/drive123-480.webp 480w,/assets/img/publication_preview/drive123-800.webp 800w,/assets/img/publication_preview/drive123-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/drive123.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="drive123.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lin2024drive123" class="col-sm-8"> <div class="title">Drive-1-to-3: Enriching Diffusion Priors for Novel View Synthesis of Real Vehicles</div> <div class="author"> Chuang Lin, Bingbing Zhuang, <em>Shanlin Sun</em>, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Ziyu Jiang, jianfei Cai, Manmohan Chandraker' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>arXiv preprint</em>, Dec 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2412.14494" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://clin1223.github.io/projects/Drive123/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">lin2024drive123</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Drive-1-to-3: Enriching Diffusion Priors for Novel View Synthesis of Real Vehicles}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lin, Chuang and Zhuang, Bingbing and Sun, Shanlin and Jiang, Ziyu and Cai, jianfei and Chandraker, Manmohan}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr24_lidarf-480.webp 480w,/assets/img/publication_preview/cvpr24_lidarf-800.webp 800w,/assets/img/publication_preview/cvpr24_lidarf-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cvpr24_lidarf.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr24_lidarf.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="sun2024lidarf" class="col-sm-8"> <div class="title">LidaRF: Delving into Lidar for Neural Radiance Field on Street Scenes</div> <div class="author"> <em>Shanlin Sun</em>, Bingbing Zhuang, Ziyu Jiang, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Buyu Liu, Xiaohui Xie, Manmohan Chandraker' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Computer Vision and Pattern Recognition</em> , Jun 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2405.00900" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://siwensun.github.io/lidarf-project/" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sun2024lidarf</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{LidaRF: Delving into Lidar for Neural Radiance Field on Street Scenes}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sun, Shanlin and Zhuang, Bingbing and Jiang, Ziyu and Liu, Buyu and Xie, Xiaohui and Chandraker, Manmohan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Computer Vision and Pattern Recognition}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{How to encode Lidar geometry guidance into NeRF training? How to deal with noisy/sparse Lidar supervision? How to augment data from Lidar data?}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> <div class="notes"> <p>How to encode Lidar geometry guidance into NeRF training? How to deal with noisy/sparse Lidar supervision? How to augment data from Lidar data?</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">MedIA</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/nir-480.webp 480w,/assets/img/publication_preview/nir-800.webp 800w,/assets/img/publication_preview/nir-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/nir.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="nir.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="sun2022medical" class="col-sm-8"> <div class="title">Medical Image Registration via Neural Fields</div> <div class="author"> <em>Shanlin Sun</em>, Kun Han, Chenyu You, and <span class="more-authors" title="click to view 8 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '8 more authors' ? 'Hao Tang, Deying Kong, Junayed Naushad, Xiangyi Yan, Haoyu Ma, Pooya Khosravi, James S Duncan, Xiaohui Xie' : '8 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">8 more authors</span> </div> <div class="periodical"> <em>Medical Image Analysis</em>, Jul 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S1361841524001749" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Siwensun/NIR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">sun2022medical</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Medical Image Registration via Neural Fields}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sun, Shanlin and Han, Kun and You, Chenyu and Tang, Hao and Kong, Deying and Naushad, Junayed and Yan, Xiangyi and Ma, Haoyu and Khosravi, Pooya and Duncan, James S and Xie, Xiaohui}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Medical Image Analysis}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Introducing neural fields into 3D medical image registration. It is lightweight and fast, can be displacement-based or velocity-based.}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> <div class="notes"> <p>Introducing neural fields into 3D medical image registration. It is lightweight and fast, can be displacement-based or velocity-based.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">BMVC</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/hybrid_csr_teaser-480.webp 480w,/assets/img/publication_preview/hybrid_csr_teaser-800.webp 800w,/assets/img/publication_preview/hybrid_csr_teaser-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/hybrid_csr_teaser.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="hybrid_csr_teaser.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="sun2023hybrid" class="col-sm-8"> <div class="title">Hybrid-CSR: Coupling Explicit and Implicit Shape Representation for Cortical Surface Reconstruction</div> <div class="author"> <em>Shanlin Sun</em>, Thanh-Tung Le, Chenyu You, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Hao Tang, Kun Han, Haoyu Ma, Deying Kong, Xiangyi Yan, Xiaohui Xie' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>In British Machine Vision Conference</em> , Nov 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2307.12299" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sun2023hybrid</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hybrid-CSR: Coupling Explicit and Implicit Shape Representation for Cortical Surface Reconstruction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sun, Shanlin and Le, Thanh-Tung and You, Chenyu and Tang, Hao and Han, Kun and Ma, Haoyu and Kong, Deying and Yan, Xiangyi and Xie, Xiaohui}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{British Machine Vision Conference}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Bridging mesh-based (explicit) and occupancy (implicit) shape representation with oriented point clouds (followed by differentiable poisson surface reconstruction) to model complex shapes with fewer local distortions.}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> <div class="notes"> <p>Bridging mesh-based (explicit) and occupancy (implicit) shape representation with oriented point clouds (followed by differentiable poisson surface reconstruction) to model complex shapes with fewer local distortions.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICLR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/iclr24_ddot-480.webp 480w,/assets/img/publication_preview/iclr24_ddot-800.webp 800w,/assets/img/publication_preview/iclr24_ddot-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/iclr24_ddot.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="iclr24_ddot.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="le2023diffeomorphic" class="col-sm-8"> <div class="title">Diffeomorphic Deformation via Sliced Wasserstein Distance Optimization for Cortical Surface Reconstruction</div> <div class="author"> Tung Le, Khai Nguyen, <em>Shanlin Sun</em>, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Kun Han, Nhat Ho, Xiaohui Xie' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In International Conference on Learning Representations</em> , Apr 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2305.17555" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">le2023diffeomorphic</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Diffeomorphic Deformation via Sliced Wasserstein Distance Optimization for Cortical Surface Reconstruction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Le, Tung and Nguyen, Khai and Sun, Shanlin and Han, Kun and Ho, Nhat and Xie, Xiaohui}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">WACV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/wacv24_hdnf-480.webp 480w,/assets/img/publication_preview/wacv24_hdnf-800.webp 800w,/assets/img/publication_preview/wacv24_hdnf-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/wacv24_hdnf.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="wacv24_hdnf.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="han2024hybrid" class="col-sm-8"> <div class="title">Hybrid Neural Diffeomorphic Flow for Shape Representation and Generation via Triplane</div> <div class="author"> Kun Han, <em>Shanlin Sun</em>, Thanh-Tung Le, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Xiangyi Yan, Haoyu Ma, Chenyu You, Xiaohui Xie' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>In Winter Conference on Applications of Computer Vision</em> , Jan 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Han_Hybrid_Neural_Diffeomorphic_Flow_for_Shape_Representation_and_Generation_via_WACV_2024_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">han2024hybrid</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hybrid Neural Diffeomorphic Flow for Shape Representation and Generation via Triplane}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Han, Kun and Sun, Shanlin and Le, Thanh-Tung and Yan, Xiangyi and Ma, Haoyu and You, Chenyu and Xie, Xiaohui}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Winter Conference on Applications of Computer Vision}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Built upon our NDF (Neural Diffeomorphic Flow), replacing global latent with triplane for more detailed shape representation.}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> <div class="notes"> <p>Built upon our NDF (Neural Diffeomorphic Flow), replacing global latent with triplane for more detailed shape representation.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">WACV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/wacv24_cvthead-480.webp 480w,/assets/img/publication_preview/wacv24_cvthead-800.webp 800w,/assets/img/publication_preview/wacv24_cvthead-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/wacv24_cvthead.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="wacv24_cvthead.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ma2024cvthead" class="col-sm-8"> <div class="title">CVTHead: One-shot Controllable Head Avatar with Vertex-feature Transformer</div> <div class="author"> Haoyu Ma, Tong Zhang, <em>Shanlin Sun</em>, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Xiangyi Yan, Kun Han, Xiaohui Xie' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Winter Conference on Applications of Computer Vision</em> , Jan 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2311.06443" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/HowieMa/CVTHead" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ma2024cvthead</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{CVTHead: One-shot Controllable Head Avatar with Vertex-feature Transformer}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ma, Haoyu and Zhang, Tong and Sun, Shanlin and Yan, Xiangyi and Han, Kun and Xie, Xiaohui}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Winter Conference on Applications of Computer Vision}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">WACV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/wacv24_aftersam-480.webp 480w,/assets/img/publication_preview/wacv24_aftersam-800.webp 800w,/assets/img/publication_preview/wacv24_aftersam-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/wacv24_aftersam.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="wacv24_aftersam.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="yan2024after" class="col-sm-8"> <div class="title">AFTer-SAM: Adapting SAM With Axial Fusion Transformer for Medical Imaging Segmentation</div> <div class="author"> Xiangyi Yan, <em>Shanlin Sun</em>, Kun Han, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Thanh-Tung Le, Haoyu Ma, Chenyu You, Xiaohui Xie' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>In Winter Conference on Applications of Computer Vision</em> , Jan 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Yan_AFTer-SAM_Adapting_SAM_With_Axial_Fusion_Transformer_for_Medical_Imaging_WACV_2024_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yan2024after</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{AFTer-SAM: Adapting SAM With Axial Fusion Transformer for Medical Imaging Segmentation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yan, Xiangyi and Sun, Shanlin and Han, Kun and Le, Thanh-Tung and Ma, Haoyu and You, Chenyu and Xie, Xiaohui}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Winter Conference on Applications of Computer Vision}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr24_eot-480.webp 480w,/assets/img/publication_preview/cvpr24_eot-800.webp 800w,/assets/img/publication_preview/cvpr24_eot-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cvpr24_eot.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr24_eot.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="le2024integrating" class="col-sm-8"> <div class="title">Integrating Efficient Optimal Transport and Functional Maps for Unsupervised Shape Correspondence Learning</div> <div class="author"> Tung Le, Khai Nguyen, <em>Shanlin Sun</em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Nhat Ho, Xiaohui Xie' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Computer Vision and Pattern Recognition</em> , Jun 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2403.01781" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">le2024integrating</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Integrating Efficient Optimal Transport and Functional Maps for Unsupervised Shape Correspondence Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Le, Tung and Nguyen, Khai and Sun, Shanlin and Ho, Nhat and Xie, Xiaohui}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Computer Vision and Pattern Recognition}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">WACV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/wacv23_dnvf-480.webp 480w,/assets/img/publication_preview/wacv23_dnvf-800.webp 800w,/assets/img/publication_preview/wacv23_dnvf-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/wacv23_dnvf.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="wacv23_dnvf.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="han2023diffeomorphic" class="col-sm-8"> <div class="title">Diffeomorphic Image Registration with Neural Velocity Field</div> <div class="author"> Kun Han, <em>Shanlin Sun</em>, Xiangyi Yan, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Chenyu You, Hao Tang, Junayed Naushad, Haoyu Ma, Deying Kong, Xiaohui Xie' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>In Winter Conference on Applications of Computer Vision</em> , Jan 2023 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content/WACV2023/papers/Han_Diffeomorphic_Image_Registration_With_Neural_Velocity_Field_WACV_2023_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">han2023diffeomorphic</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Diffeomorphic Image Registration with Neural Velocity Field}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Han, Kun and Sun, Shanlin and Yan, Xiangyi and You, Chenyu and Tang, Hao and Naushad, Junayed and Ma, Haoyu and Kong, Deying and Xie, Xiaohui}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Winter Conference on Applications of Computer Vision}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Taking a neural velocity field as the test time optimization module on top of learning-based methods for fast and accurate diffeomorphic image registration.}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> <div class="notes"> <p>Taking a neural velocity field as the test time optimization module on top of learning-based methods for fast and accurate diffeomorphic image registration.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">MICCAI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/miccai23_medgen3d-480.webp 480w,/assets/img/publication_preview/miccai23_medgen3d-800.webp 800w,/assets/img/publication_preview/miccai23_medgen3d-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/miccai23_medgen3d.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="miccai23_medgen3d.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="han2023medgen3d" class="col-sm-8"> <div class="title">Medgen3d: A Deep Generative Framework for Paired 3d Image and Mask Generation</div> <div class="author"> Kun Han, Yifeng Xiong, Chenyu You, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Pooya Khosravi, Shanlin Sun, Xiangyi Yan, James S Duncan, Xiaohui Xie' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>In International Conference on Medical Image Computing and Computer-Assisted Intervention</em> , Oct 2023 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2304.04106" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">han2023medgen3d</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Medgen3d: A Deep Generative Framework for Paired 3d Image and Mask Generation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Han, Kun and Xiong, Yifeng and You, Chenyu and Khosravi, Pooya and Sun, Shanlin and Yan, Xiangyi and Duncan, James S and Xie, Xiaohui}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Medical Image Computing and Computer-Assisted Intervention}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/lfd-teaser-480.webp 480w,/assets/img/publication_preview/lfd-teaser-800.webp 800w,/assets/img/publication_preview/lfd-teaser-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/lfd-teaser.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="lfd-teaser.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xiong2023light" class="col-sm-8"> <div class="title">Light Field Diffusion for Single-view Novel View Synthesis</div> <div class="author"> Yifeng Xiong, Haoyu Ma, <em>Shanlin Sun</em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Kun Han, Xiaohui Xie' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>arXiv preprint</em>, Sep 2023 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2309.11525" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://lightfielddiffusion.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">xiong2023light</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Light Field Diffusion for Single-view Novel View Synthesis}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xiong, Yifeng and Ma, Haoyu and Sun, Shanlin and Han, Kun and Xie, Xiaohui}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cvpr22_ndf-480.webp 480w,/assets/img/publication_preview/cvpr22_ndf-800.webp 800w,/assets/img/publication_preview/cvpr22_ndf-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cvpr22_ndf.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cvpr22_ndf.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="sun2022topology" class="col-sm-8"> <div class="title">Topology-preserving Shape Reconstruction and Registration via Neural Diffeomorphic Flow</div> <div class="author"> <em>Shanlin Sun</em>, Kun Han, Deying Kong, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Hao Tang, Xiangyi Yan, Xiaohui Xie' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Computer Vision and Patern Recognition</em> , Jun 2022 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2203.08652" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Siwensun/Neural_Diffeomorphic_Flow%E2%80%93NDF" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sun2022topology</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Topology-preserving Shape Reconstruction and Registration via Neural Diffeomorphic Flow}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sun, Shanlin and Han, Kun and Kong, Deying and Tang, Hao and Yan, Xiangyi and Xie, Xiaohui}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Computer Vision and Patern Recognition}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Introcuding topology preserving to template-based deep implicit shape representation via Neural ODE.}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> <div class="notes"> <p>Introcuding topology preserving to template-based deep implicit shape representation via Neural ODE.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">WACV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/wacv22_afterunet-480.webp 480w,/assets/img/publication_preview/wacv22_afterunet-800.webp 800w,/assets/img/publication_preview/wacv22_afterunet-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/wacv22_afterunet.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="wacv22_afterunet.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="yan2022after" class="col-sm-8"> <div class="title">After-unet: Axial Fusion Transformer Unet for Medical Image Segmentation</div> <div class="author"> Xiangyi Yan, Hao Tang, <em>Shanlin Sun</em>, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Haoyu Ma, Deying Kong, Xiaohui Xie' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Winter Conference on Applications of Computer Vision</em> , Jan 2022 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content/WACV2022/papers/Yan_AFTer-UNet_Axial_Fusion_Transformer_UNet_for_Medical_Image_Segmentation_WACV_2022_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yan2022after</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{After-unet: Axial Fusion Transformer Unet for Medical Image Segmentation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yan, Xiangyi and Tang, Hao and Sun, Shanlin and Ma, Haoyu and Kong, Deying and Xie, Xiaohui}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Winter Conference on Applications of Computer Vision}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">R&amp;O</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/r&amp;o21_wbnet-480.webp 480w,/assets/img/publication_preview/r&amp;o21_wbnet-800.webp 800w,/assets/img/publication_preview/r&amp;o21_wbnet-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/r&amp;o21_wbnet.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="r&amp;o21_wbnet.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="chen2021deep" class="col-sm-8"> <div class="title">A Deep Learning-based Auto-segmentation System for Organs-at-risk on Whole-body Computed Tomography Images for Radiation Therapy</div> <div class="author"> Xuming Chen, <em>Shanlin Sun</em>, Narisu Bai, and <span class="more-authors" title="click to view 8 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '8 more authors' ? 'Kun Han, Qianqian Liu, Shengyu Yao, Hao Tang, Chupeng Zhang, Zhipeng Lu, Qian Huang, others' : '8 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">8 more authors</span> </div> <div class="periodical"> <em>Radiotherapy and Oncology</em>, Jan 2021 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S0167814021062174" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">chen2021deep</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Deep Learning-based Auto-segmentation System for Organs-at-risk on Whole-body Computed Tomography Images for Radiation Therapy}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xuming and Sun, Shanlin and Bai, Narisu and Han, Kun and Liu, Qianqian and Yao, Shengyu and Tang, Hao and Zhang, Chupeng and Lu, Zhipeng and Huang, Qian and others}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Radiotherapy and Oncology}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{160}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{175--184}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Segmenting more than 50 organs from whole body CT images. It is the core algorithm of a FDA-approved product.}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> <div class="notes"> <p>Segmenting more than 50 organs from whole body CT images. It is the core algorithm of a FDA-approved product.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/iccv22_rpnet-480.webp 480w,/assets/img/publication_preview/iccv22_rpnet-800.webp 800w,/assets/img/publication_preview/iccv22_rpnet-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/iccv22_rpnet.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="iccv22_rpnet.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="tang2021recurrent" class="col-sm-8"> <div class="title">Recurrent Mask Refinement for Few-shot Medical Image Segmentation</div> <div class="author"> Hao Tang, Xingwei Liu, <em>Shanlin Sun</em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Xiangyi Yan, Xiaohui Xie' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In International Conference on Computer Vision</em> , Oct 2021 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Tang_Recurrent_Mask_Refinement_for_Few-Shot_Medical_Image_Segmentation_ICCV_2021_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/uci-cbcl/RP-Net" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">tang2021recurrent</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Recurrent Mask Refinement for Few-shot Medical Image Segmentation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tang, Hao and Liu, Xingwei and Sun, Shanlin and Yan, Xiangyi and Xie, Xiaohui}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Computer Vision}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Shanlin Sun (孙 山林). Last updated: November 08, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?06cae41083477f121be8cd9797ad8e2f"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-cv",title:"cv",description:"The PDF is probably easier to read.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:"Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra",description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:"Displaying External Posts on Your al-folio Blog",description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"news-our-work-lt-a-href-quot-https-gabrie-l-github-io-coma-page-quot-gt-coma-lt-a-gt-on-human-motion-generation-via-multi-modal-agents-was-accepted-at-aaai-2026",title:"Our work &lt;a href=&quot;https://gabrie-l.github.io/coma-page/&quot;&gt;CoMA&lt;/a&gt; on human motion generation via multi-modal agents was accepted at AAAI 2026.",description:"",section:"News"},{id:"news-join-meta-as-research-scientist",title:"Join Meta as Research Scientist.",description:"",section:"News"},{id:"news-successfully-defense-my-phd-thesis-towards-world-simulation-object-human-and-scene-modeling-with-neural-networks-committee-members-prof-lt-a-href-quot-https-ics-uci-edu-xhx-quot-gt-xiaohui-xie-lt-a-gt-chair-prof-lt-a-href-quot-http-acberg-com-quot-gt-alexander-c-berg-lt-a-gt-and-prof-lt-a-href-quot-https-ics-uci-edu-fowlkes-quot-gt-charless-c-fowlkes-lt-a-gt",title:"Successfully defense my PhD thesis \u201cTowards World Simulation: Object, Human and Scene Modeling with Neural Networks\u201d. Committee members: Prof. &lt;a href=&quot;https://ics.uci.edu/~xhx/&quot;&gt;Xiaohui Xie&lt;/a&gt; (Chair), Prof. &lt;a href=&quot;http://acberg.com/&quot;&gt;Alexander C. Berg&lt;/a&gt; and Prof. &lt;a href=&quot;https://ics.uci.edu/~fowlkes/&quot;&gt;Charless C. Fowlkes&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-work-lt-a-href-quot-https-siwensun-github-io-ouroboros-project-quot-gt-ouroboros-lt-a-gt-on-cycle-consistent-rendering-via-diffusion-models-was-accepted-at-iccv-2025",title:"Our work &lt;a href=&quot;https://siwensun.github.io/ouroboros-project/&quot;&gt;Ouroboros&lt;/a&gt; on cycle-consistent rendering via diffusion models was accepted at ICCV 2025.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-arxiv-org-pdf-2307-12299-quot-gt-hybrid-csr-lt-a-gt-was-accepted-as-oral-presentation-at-bmvc-2024",title:"Our paper &lt;a href=&quot;https://arxiv.org/pdf/2307.12299&quot;&gt;Hybrid-CSR&lt;/a&gt; was accepted as oral presentation at BMVC 2024.",description:"",section:"News"},{id:"news-after-two-year-revisions-our-paper-lt-a-href-quot-https-www-sciencedirect-com-science-article-pii-s1361841524001749-quot-gt-medical-image-registration-via-neural-fields-lt-a-gt-is-finally-published-in-lt-a-href-quot-https-www-sciencedirect-com-journal-medical-image-analysis-quot-gt-medical-image-analysis-lt-a-gt",title:"After two-year revisions, our paper &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S1361841524001749&quot;&gt;\u201cMedical Image Registration via Neural Fields\u201d&lt;/a&gt; is finally published in &lt;a href=&quot;https://www.sciencedirect.com/journal/medical-image-analysis&quot;&gt;Medical Image Analysis&lt;/a&gt;!",description:"",section:"News"},{id:"news-join-nec-labs-america-as-research-intern-in-media-analytics-team-mentored-by-lt-a-href-quot-https-bbzh-github-io-quot-gt-bingbing-zhuang-lt-a-gt",title:"Join NEC Labs America as Research Intern in Media Analytics team, mentored by &lt;a href=&quot;https://bbzh.github.io/&quot;&gt;Bingbing Zhuang&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-openaccess-thecvf-com-content-cvpr2024-papers-sun-lidarf-delving-into-lidar-for-neural-radiance-field-on-street-cvpr-2024-paper-pdf-quot-gt-lidarf-delving-into-lidar-for-neural-radiance-field-on-street-scenes-lt-a-gt-was-selected-as-highlights-of-cvpr-2024-and-will-be-oral-presented-at-lt-a-href-quot-https-agents4ad-github-io-quot-gt-cvpr-2024-workshop-ddads-lt-a-gt",title:"Our paper &lt;a href=&quot;https://openaccess.thecvf.com/content/CVPR2024/papers/Sun_LidaRF_Delving_into_Lidar_for_Neural_Radiance_Field_on_Street_CVPR_2024_paper.pdf&quot;&gt;\u201cLidaRF: Delving into Lidar for Neural Radiance Field on Street Scenes\u201d&lt;/a&gt; was selected as highlights of CVPR 2024 and will be oral presented at &lt;a href=&quot;https://agents4ad.github.io/&quot;&gt;CVPR 2024 Workshop DDADS&lt;/a&gt;.",description:"",section:"News"},{id:"news-pass-my-advancement-exam-committee-members-prof-lt-a-href-quot-https-ics-uci-edu-xhx-quot-gt-xiaohui-xie-lt-a-gt-chair-prof-lt-a-href-quot-http-acberg-com-quot-gt-alexander-c-berg-lt-a-gt-prof-lt-a-href-quot-https-ics-uci-edu-ihler-index-html-quot-gt-alexander-ihler-lt-a-gt-and-prof-lt-a-href-quot-https-sites-google-com-uci-edu-yanning-shen-home-quot-gt-yanning-shen-lt-a-gt",title:"Pass my advancement exam. Committee members: Prof. &lt;a href=&quot;https://ics.uci.edu/~xhx/&quot;&gt;Xiaohui Xie&lt;/a&gt; (Chair), Prof. &lt;a href=&quot;http://acberg.com/&quot;&gt;Alexander C. Berg&lt;/a&gt;, Prof. &lt;a href=&quot;https://ics.uci.edu/~ihler/index.html&quot;&gt;Alexander Ihler&lt;/a&gt; and Prof. &lt;a href=&quot;https://sites.google.com/uci.edu/yanning-shen/home&quot;&gt;Yanning Shen&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-openaccess-thecvf-com-content-cvpr2024-papers-sun-lidarf-delving-into-lidar-for-neural-radiance-field-on-street-cvpr-2024-paper-pdf-quot-gt-lidarf-delving-into-lidar-for-neural-radiance-field-on-street-scenes-lt-a-gt-and-lt-a-href-quot-https-openaccess-thecvf-com-content-cvpr2024-papers-le-integrating-efficient-optimal-transport-and-functional-maps-for-unsupervised-shape-cvpr-2024-paper-pdf-quot-gt-integrating-efficient-optimal-transport-and-functional-maps-for-unsupervised-shape-correspondence-learning-lt-a-gt-were-accepted-at-cvpr-2024",title:"Our paper &lt;a href=&quot;https://openaccess.thecvf.com/content/CVPR2024/papers/Sun_LidaRF_Delving_into_Lidar_for_Neural_Radiance_Field_on_Street_CVPR_2024_paper.pdf&quot;&gt;\u201cLidaRF: Delving into Lidar for Neural Radiance Field on Street Scenes\u201d&lt;/a&gt; and &lt;a href=&quot;https://openaccess.thecvf.com/content/CVPR2024/papers/Le_Integrating_Efficient_Optimal_Transport_and_Functional_Maps_For_Unsupervised_Shape_CVPR_2024_paper.pdf&quot;&gt;\u201cIntegrating efficient optimal transport and functional maps for unsupervised shape correspondence learning\u201d&lt;/a&gt; were accepted at CVPR 2024.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-openreview-net-forum-id-gxhrr8vuqb-quot-gt-diffeomorphic-mesh-deformation-via-efficient-optimal-transport-for-cortical-surface-reconstruction-lt-a-gt-was-accepted-at-iclr-2024",title:"Our paper &lt;a href=&quot;https://openreview.net/forum?id=gxhRR8vUQb&quot;&gt;\u201cDiffeomorphic Mesh Deformation via Efficient Optimal Transport for Cortical Surface Reconstruction\u201d&lt;/a&gt; was accepted at ICLR 2024.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-openaccess-thecvf-com-content-wacv2024-papers-yan-after-sam-adapting-sam-with-axial-fusion-transformer-for-medical-imaging-wacv-2024-paper-pdf-quot-gt-after-sam-lt-a-gt-lt-a-href-quot-https-openaccess-thecvf-com-content-wacv2024-papers-ma-cvthead-one-shot-controllable-head-avatar-with-vertex-feature-transformer-wacv-2024-paper-pdf-quot-gt-cvthead-lt-a-gt-and-lt-a-href-quot-https-openaccess-thecvf-com-content-wacv2024-papers-han-hybrid-neural-diffeomorphic-flow-for-shape-representation-and-generation-via-wacv-2024-paper-pdf-quot-gt-hndf-lt-a-gt-were-accepted-at-wacv-2024",title:"Our paper &lt;a href=&quot;https://openaccess.thecvf.com/content/WACV2024/papers/Yan_AFTer-SAM_Adapting_SAM_With_Axial_Fusion_Transformer_for_Medical_Imaging_WACV_2024_paper.pdf&quot;&gt;AFTer-SAM&lt;/a&gt;, &lt;a href=&quot;https://openaccess.thecvf.com/content/WACV2024/papers/Ma_CVTHead_One-Shot_Controllable_Head_Avatar_With_Vertex-Feature_Transformer_WACV_2024_paper.pdf&quot;&gt;CVTHead&lt;/a&gt; and &lt;a href=&quot;https://openaccess.thecvf.com/content/WACV2024/papers/Han_Hybrid_Neural_Diffeomorphic_Flow_for_Shape_Representation_and_Generation_via_WACV_2024_paper.pdf&quot;&gt;HNDF&lt;/a&gt; were accepted at WACV 2024.",description:"",section:"News"},{id:"news-join-nec-labs-america-as-research-intern-in-media-analytics-team-mentored-by-lt-a-href-quot-https-bbzh-github-io-quot-gt-bingbing-zhuang-lt-a-gt-and-lt-a-href-quot-https-geekjzy-github-io-quot-gt-ziyu-jiang-lt-a-gt",title:"Join NEC Labs America as Research Intern in Media Analytics team, mentored by &lt;a href=&quot;https://bbzh.github.io/&quot;&gt;Bingbing Zhuang&lt;/a&gt; and &lt;a href=&quot;https://geekjzy.github.io/&quot;&gt;Ziyu Jiang&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-arxiv-org-pdf-2304-04106-quot-gt-medgen3d-a-deep-generative-framework-for-paired-3d-image-and-mask-generation-lt-a-gt-and-lt-a-href-quot-https-arxiv-org-pdf-2304-03406-quot-gt-localized-region-contrast-for-enhancing-self-supervised-learning-in-medical-image-segmentation-lt-a-gt-were-accepted-at-lt-a-href-quot-https-conferences-miccai-org-2023-en-quot-gt-miccai-2023-lt-a-gt",title:"Our paper &lt;a href=&quot;https://arxiv.org/pdf/2304.04106&quot;&gt;\u201cMedgen3d: A deep generative framework for paired 3d image and mask generation\u201d&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/pdf/2304.03406&quot;&gt;\u201cLocalized Region Contrast for Enhancing Self-supervised Learning in Medical Image Segmentation\u201d&lt;/a&gt; were accepted at &lt;a href=&quot;https://conferences.miccai.org/2023/en/&quot;&gt;MICCAI 2023&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-openaccess-thecvf-com-content-wacv2023-papers-han-diffeomorphic-image-registration-with-neural-velocity-field-wacv-2023-paper-pdf-quot-gt-diffeomorphic-image-registration-with-neural-velocity-field-lt-a-gt-and-lt-a-href-quot-https-openaccess-thecvf-com-content-wacv2023-papers-yan-representation-recovering-for-self-supervised-pre-training-on-medical-images-wacv-2023-paper-pdf-quot-gt-representation-recovering-for-self-supervised-pre-training-on-medical-images-lt-a-gt-were-accepted-at-wacv-2023",title:"Our paper &lt;a href=&quot;https://openaccess.thecvf.com/content/WACV2023/papers/Han_Diffeomorphic_Image_Registration_With_Neural_Velocity_Field_WACV_2023_paper.pdf&quot;&gt;\u201cDiffeomorphic Image Registration with Neural Velocity Field\u201d&lt;/a&gt; and &lt;a href=&quot;https://openaccess.thecvf.com/content/WACV2023/papers/Yan_Representation_Recovering_for_Self-Supervised_Pre-Training_on_Medical_Images_WACV_2023_paper.pdf&quot;&gt;\u201cRepresentation recovering for self-supervised pre-training on medical images\u201d&lt;/a&gt; were accepted at WACV 2023.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-arxiv-org-pdf-2209-10840-quot-gt-identity-aware-hand-mesh-estimation-and-personalization-from-rgb-images-lt-a-gt-was-accepted-at-eccv-2022",title:"Our paper &lt;a href=&quot;https://arxiv.org/pdf/2209.10840&quot;&gt;\u201cIdentity-aware hand mesh estimation and personalization from rgb images\u201d&lt;/a&gt; was accepted at ECCV 2022.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-openaccess-thecvf-com-content-cvpr2022-papers-sun-topology-preserving-shape-reconstruction-and-registration-via-neural-diffeomorphic-flow-cvpr-2022-paper-pdf-quot-gt-topology-preserving-shape-reconstruction-and-registration-via-neural-diffeomorphic-flow-lt-a-gt-was-accepted-at-cvpr-2022",title:"Our paper &lt;a href=&quot;https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Topology-Preserving_Shape_Reconstruction_and_Registration_via_Neural_Diffeomorphic_Flow_CVPR_2022_paper.pdf&quot;&gt;\u201cTopology-preserving shape reconstruction and registration via neural diffeomorphic flow\u201d&lt;/a&gt; was accepted at CVPR 2022.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-openaccess-thecvf-com-content-wacv2022-papers-yan-after-unet-axial-fusion-transformer-unet-for-medical-image-segmentation-wacv-2022-paper-pdf-quot-gt-after-unet-axial-fusion-transformer-unet-for-medical-image-segmentation-lt-a-gt-was-accepted-at-wacv-2022",title:"Our paper &lt;a href=&quot;https://openaccess.thecvf.com/content/WACV2022/papers/Yan_AFTer-UNet_Axial_Fusion_Transformer_UNet_for_Medical_Image_Segmentation_WACV_2022_paper.pdf&quot;&gt;\u201cAfter-unet: Axial fusion transformer unet for medical image segmentation\u201d&lt;/a&gt; was accepted at WACV 2022.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-www-sciencedirect-com-science-article-pii-s0167814021062174-quot-gt-a-deep-learning-based-auto-segmentation-system-for-organs-at-risk-on-whole-body-computed-tomography-images-for-radiation-therapy-lt-a-gt-was-accepted-at-lt-a-href-quot-https-www-sciencedirect-com-journal-radiotherapy-and-oncology-quot-gt-radiotherapy-and-oncology-lt-a-gt",title:"Our paper &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0167814021062174&quot;&gt;\u201cA deep learning-based auto-segmentation system for organs-at-risk on whole-body computed tomography images for radiation therapy\u201d&lt;/a&gt; was accepted at &lt;a href=&quot;https://www.sciencedirect.com/journal/radiotherapy-and-oncology&quot;&gt;Radiotherapy and Oncology&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-paper-lt-a-href-quot-https-arxiv-org-pdf-2001-04446-quot-gt-attentionanatomy-a-unified-framework-for-whole-body-organs-at-risk-segmentation-using-multiple-partially-annotated-datasets-lt-a-gt-was-accepted-at-lt-a-href-quot-https-biomedicalimaging-org-2020-wp-content-uploads-static-html-to-wp-data-dff0d41695bbae509355435cd32ecf5d-index-htm-quot-gt-isbi-2020-lt-a-gt",title:"Our paper &lt;a href=&quot;https://arxiv.org/pdf/2001.04446&quot;&gt;\u201cAttentionanatomy: A Unified Framework for Whole-Body Organs at Risk Segmentation Using Multiple Partially Annotated Datasets\u201d&lt;/a&gt; was accepted at &lt;a href=&quot;https://biomedicalimaging.org/2020/wp-content/uploads/static-html-to-wp/data/dff0d41695bbae509355435cd32ecf5d/index.htm&quot;&gt;ISBI 2020&lt;/a&gt;.",description:"",section:"News"},{id:"news-i-will-be-attending-university-of-california-irvine-for-a-cs-ph-d-this-fall-i-ll-be-working-at-the-intersection-of-deep-learning-and-medical-image-analysis-under-advisement-from-prof-lt-a-href-quot-https-ics-uci-edu-xhx-quot-gt-xiaohui-xie-lt-a-gt",title:"I will be attending University of California, Irvine for a CS Ph.D. this Fall. I\u2019ll be working at the intersection of deep learning and medical image analysis under advisement from Prof. &lt;a href=&quot;https://ics.uci.edu/~xhx/&quot;&gt;Xiaohui Xie&lt;/a&gt;.",description:"",section:"News"},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%73%68%61%6E%6C%69%6E%73[%61%74]%75%63%69[%64%6F%74]%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=c6wKvwgAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Siwensun","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/shanlin-sun/","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>